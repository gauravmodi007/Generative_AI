{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\n\nimport pandas as pd\nimport tiktoken\nfrom openai import OpenAI\n\n\ndef create_train_val_test_split(medical_report):\n    \"\"\"Create train, validation and test splits from the data\n\n    Args:\n        medical_report (df): Dataframe containing the data\n\n    Returns:\n        tuple: Train, validation and test dataframes\n    \"\"\"\n    grouped_data = medical_reports.groupby(\"medical_specialty\").sample(110, random_state=42) # Sample 110 items from each class\n\n    val_test_data = grouped_data.groupby(\"medical_specialty\").sample(10, random_state=42)  # sample 10 items from the above data\n    val = val_test_data.groupby(\"medical_specialty\").head(5) # Take the first 5 of each class\n    test = val_test_data.groupby(\"medical_specialty\").tail(5) # Take the last 5 of each class\n\n    train = grouped_data[~grouped_data.index.isin(val_test_data.index)] # Take the remaining ones for training\n\n    return train, val, test\n\n\ndef num_tokens_from_string(string: str) -> int:\n    \"\"\"Returns the number of tokens in a text string.\n    (https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\"\"\"\n    encoding = tiktoken.get_encoding(\"cl100k_base\")  # encoding for currently all models\n    num_tokens = len(encoding.encode(string))\n    return num_tokens\n\ndef calculate_price(train_df, price_model=0.0080):\n    \"\"\"Calculate the price for fine-tuning the model\n\n    Args:\n        train_df (dataframe): Dataframe containing the training data\n        price_model (float, optional): Price per 1k tokens. Defaults to 0.0080.\n    \"\"\"\n    report_lengths = train_df['report'].apply(lambda x: num_tokens_from_string(x))\n    avg_report_length = report_lengths.mean()\n    min_report_length = report_lengths.min()\n    max_report_length = report_lengths.max()\n    report_length_sum = report_lengths.sum()\n\n    print(f\"Average report length: {avg_report_length:.2f} tokens\")\n    print(f\"Minimum report length: {min_report_length} tokens\")\n    print(f\"Maximum report length: {max_report_length} tokens\")\n    print(f\"# The training dataset consists of: {report_length_sum} tokens\")\n\n    price_per_epoch = (report_length_sum / 1000) * price_model \n    print(f\"Fine-tuning costs ~ ${price_per_epoch:.2f} per epoch\") \n\ndef ask_to_continue():\n    \"\"\"Ask the user if they want to continue\"\"\"\n    answer = input(\"Do you want to continue? [y/n]: \")\n    if answer == 'y':\n        return True\n    else:\n        return False\n    \ndef df_to_format(df, system_prompt):\n    \"\"\"Convert the dataframe to the required format\n\n    Args:\n        df (dataframe): Dataframe containing the data\n        system_prompt (string): System prompt for the chat model\n\n    Returns:\n        list: List of dictionaries containing the formatted data\n    \"\"\"\n    formatted_data = []\n    \n    # Iterate over each row in the dataframe\n    for index, row in df.iterrows():\n        entry = {\"messages\": [{\"role\": \"system\", \"content\": system_prompt},\n                              {\"role\": \"user\", \"content\": row[\"report\"]},\n                              {\"role\": \"assistant\", \"content\": row[\"medical_specialty\"]}]}\n\n        formatted_data.append(entry)\n\n    return formatted_data\n\n\ndef to_jsonl(data, filename):\n    \"\"\"Write the data to a jsonl file\n\n    Args:\n        data (list): List of dictionaries containing the data\n        filename (string): Name of the file to write to\n    \"\"\"\n    with open(filename, 'w') as f:\n        for entry in data:\n            f.write(json.dumps(entry))\n            f.write(\"\\n\")\n\ndef check_num_tokens(prompt):\n    \"\"\"Check if the number of tokens in the prompt exceeds the limit\n\n    Args:\n        prompt (chatPrompt): Prompt to check\n\n    Returns:\n        bool: True if the number of tokens is less than 4000, False otherwise\n    \"\"\"\n    prompt_text = \" \".join([content[\"content\"] for content in prompt[\"messages\"]])\n    tokens = num_tokens_from_string(prompt_text)\n    if tokens > 4000: # according to https://platform.openai.com/docs/guides/fine-tuning/token-limits\n        print(f\"Prompt {prompt} exceeds token limit!\")\n        return False\n    return True\n\ndef check_prompt(prompt):\n    \"\"\"Check if the prompt is valid\n\n    Args:\n        prompt (chatPrompt): Prompt to check\n\n    Returns:\n        bool: True if the prompt is valid, False otherwise\n    \"\"\"\n    if len(prompt[\"messages\"][1][\"content\"]):\n        if len(prompt[\"messages\"][2][\"content\"]):\n            return True\n    print(f\"Prompt {prompt} is missing data!\")\n    return False\n\ndef validate_data(path_to_jsonl):\n    with open(path_to_jsonl, 'r') as f:\n        dataset = [json.loads(line) for line in f]\n    for element in dataset:\n        assert check_num_tokens(element) and check_prompt(element)\n        \n\n\n\nif __name__ == '__main__':\n\n    # Load the data\n    medical_reports = pd.read_csv('reports.csv')  # Change accordingly to your data\n    \n    # Dropping rows where 'report' is missing\n    medical_reports.dropna(subset=['report'], inplace=True)\n    medical_reports.info()\n\n    # Create train, validation and test splits\n    train, val, test = create_train_val_test_split(medical_reports)\n\n    # Calculate the price for fine-tuning\n    calculate_price(train)\n\n    # Ask the user if they want to continue\n    if not ask_to_continue():\n        print(\"Exiting...\")\n        exit()\n\n    # Define the system prompt\n    system_prompt = \"Given the medical description report, classify it into one of these categories: \" + \\\n                 \"[Cardiovascular / Pulmonary, Gastroenterology, Neurology, Radiology, Surgery]\"\n    \n    # Convert the dataframes to the required format\n    train_formatted = df_to_format(train, system_prompt)\n\n    # Write the data to jsonl files\n    to_jsonl(train_formatted, \"train_data.jsonl\")\n\n    # Perform the same steps for validation data\n    val_formatted = df_to_format(val, system_prompt)\n    to_jsonl(val_formatted, \"val_data.jsonl\")\n\n    # Validate the data\n    validate_data(\"train_data.jsonl\")\n    validate_data(\"val_data.jsonl\")\n\n    ################## TRAINING ##################\n    client = OpenAI(api_key=\"\")\n\n    # Upload train files to OpenAI\n    file_upload_response = client.files.create(\n                            file=open(\"train_data.jsonl\", \"rb\"),\n                            purpose='fine-tune')\n    # Upload validation files to OpenAI\n    file_upload_response_val = client.files.create(\n                            file=open(\"val_data.jsonl\", \"rb\"),\n                            purpose='fine-tune')\n    # Start fine-tuning\n    fine_tuning_response = client.fine_tuning.jobs.create(training_file=file_upload_response.id,\n                            model=\"gpt-3.5-turbo\",\n                            hyperparameters={\"n_epochs\": 1},\n                            validation_file = file_upload_response_val.id)\n","metadata":{},"execution_count":null,"outputs":[]}]}